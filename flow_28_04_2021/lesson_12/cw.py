"""
1. Сделать шаблоны для отображения сотрудников, заявок и департаментов и прикрутить их к соответствующим методам.
Используйте 1 базовый шаблон, от которого унаследуете все остальные.

2.
- Написать ручку на flask, которая будет принимать в теле запроса список id пользователей.
- Дальше по каждому id нужно ОТДЕЛЬНО сделать запрос в БД на получение информации о пользователе.
- Реализовать механизм сбора данных о пользователе через процессы или потоки.
- Получив информацию по каждому пользователю вернуть её в составе json-объекта в ответе.
"""

# Процесс - программа, которая запущена в оперативной памяти компьютера. Другими словами, процесс - это набор
# инструкций, которые выполняются последовательно (в общем случае). В реальности всё немного не так просто.
# характеристики процесса:
# - PID - идентификатор процесса
# - Объём оперативной памяти, который занимает процесс
# - Стек (для вызова функций и переменных)
# Список открытых файлов
# Ввод/вывод

# TOP - команда, которая покажетю какие процессы сейчас запущены (запускаем команду в терминале)
# Кажется, что все процессы работают одновременно, но это не так. На самом деле планировщик выделяет каждому
# процессу небольшой квант времени, в ходе которого процесс выполняется, а потом происходит переключение.

# ЗАПУСТИМ НАШ ПЕРВЫЙ ПРОЦЕСС
import time
import os

# pid = os.getpid()  # получаем id процесса, в котором запущена программа

# while True:
#     print(pid, time.time())
#     time.sleep(2)

# ps axu - покажет информацию о процессах, запущенных в системе
# ps axu | grep lesson_12.py

# последовательность команд, которые выполняет процесс:
# процесс делает такую штуку, как системный вызов. Системный вызов выполняется ядром ОС, а результат возвращается
# в процесс, который этот системный вызов совершил. Пример системного вызова - вывод информации в консоль.

# чтобы посмотреть, какие системные вызовы делает наш процесс, мы можем запустить команду в терминале:
# strace -p <номер процесса>

# список открытых процессом файлов:
# lsof -p <номер процесса>

# перенаправление вывода в файл python cw.py > log.txt


# СОЗДАНИЕ ПРОЦЕССОВ
# import time
# import os
#
# pid = os.fork()  # создать точную копию родительского процесса, полностью
# # копирует все ресурсы родителя
# if pid == 0:  # id дочернего процесса будет всегда 0
#     # этот код будет исполнен в дочернем процессе
#     while True:
#         print("child:", os.getpid())
#         time.sleep(2)
# else:
#     # этот код будет исполнен в родительском процессе
#     print("parent:", os.getpid())
#     os.wait()  # дожидаемся завершения дочернего процесса

# РАБОТА ПАМЯТИ В ПРОЦЕССАХ
# import os
#
# foo = "bar"
#
# if os.fork() == 0:  # память целиком будет скопирована для дочернего процесса
#     # код будет выполнен в дочернем процессе
#     foo = "baz"
#     print("child", foo)
# else:
#     # код будет выполнен в родительском процессе
#     print("parent:", foo)  # то, что в дочке поменялось значение никак не повлияет на родителя
#     os.wait()

# аналогично с файловыми дескрипторами:
# import os
#
# f = open("data.txt")
# foo = f.readline()  # считали одну строчку
#
# if os.fork() == 0:
#     # код будет выполнен в дочернем процессе
#     foo = f.readline()  # считали ещё одну строчку
#     print("child", foo)
# else:
#     # код будет выполнен в родительском процессе
#     foo = f.readline()  # считали ещё одну строчку
#     print("parent", foo)


# В питон для создания процессов и работы с ними используют модель multiprocessing
# from multiprocessing import Process
#
#
# def f(name):
#     print("hello", name)
#
#
# p = Process(target=f, args=("Bob", ))  # создаём объект, в котором хотим запустить функцию с параметрами
# p.start()  # тут будет под капотом форкнут процесс и в нём выполнена функция с параметрами
# p.join()  # ожидание завершения всех дочерних процессов

# ХОЗЯЙКЕ НА ЗАМЕТКУ: не во всех системах есть системные вызовы fork, поэтому юзать multiprocessing - это хорошо!
# Все делают за нас!


# Альтернативный способ создания процессов:
# from multiprocessing import Process
# num_list = [x for x in range(10)]
#
#
# class MyShinyProcess(Process):
#     def __init__(self, name):
#         super().__init__()
#         self.name = name
#
#     def run(self):
#         global num_list
#         proc_num = num_list.pop()
#         print("hello", self.name, proc_num)
#         time.sleep(1)
#         if len(num_list) != 0:
#             p = MyShinyProcess("Mike")
#             p.start()
#             p.join()  # важно ждать завершения работы дочернего процесса, чтобы контролировать
#             # распределение ресурсов
#         print("%d FINISHED!" % proc_num)
#
#
# p = MyShinyProcess("Mike")
# p.start()
# p.join()

# простое применение - хотим читать файл параллельно в нескольких процессах и что-то делать с прочитанными данными

# ПОТОКИ
# Потоки напоминают процессы.
# - у потока своя последовательность инструкций
# - каждый поток имеет свой стек
# - потоки принадлежат процессу (если процесс один, то все потоки принадлежат ему)
# - потоки разделяют память и ресурсы процесса
# - управлением потоками руководит ОС
# - в Python потоки имеют ограничения, связанные с GIL (об этом позже)

# from threading import Thread
#
#
# def f(name):
#     print("hello", name)

#
#
# th = Thread(target=f, args=("Bob", ))
# th.start()  # запускаем поток на исполнение
# th.join()  # дожидаемся выполнения всех созданных потоков

# альтернатива:
# from threading import Thread
#
#
# class MyShinyThread(Thread):
#     def __init__(self, name):
#         super().__init__()
#         self.name = name
#
#     def run(self):
#         print("hello", self.name)
#
#
# th = MyShinyThread("Bob")
# th.start()  # запускаем поток на исполнение
# th.join()  # дожидаемся выполнения всех созданных потоков

# простое применение - хотим читать файл с общим прогрессом и что-то делать с вычитанными данными

# Пул потоков
# from concurrent.futures import ThreadPoolExecutor, as_completed
# from random import randrange
#
# b = 0
#
#
# def f(a):
#     global b
#     print("This is %d" % b)
#     b += 1
#     # sleep_time = randrange(0, 10)
#     # time.sleep(sleep_time)
#     sleep_time = 1
#     time.sleep(sleep_time)
#     buf = b
#     return f"result {a * a} for thread {buf} which slept {sleep_time}"
#
#
# with ThreadPoolExecutor(max_workers=50) as pool:  # тут всё само сделается!
#     results = [pool.submit(f, i) for i in range(10)] # submit - создает футуру, это объект, который обещает исполнится
#
#     for future in as_completed(results):
#         print(future.result())


# Синхронизация потоков
# Этот механизм позволяет потокам обмениваться данными между собой

# Очередь
# from queue import Queue
# from threading import Thread
#
#
# def worker(q, n):
#     while True:
#         item = q.get()
#         if item is None:
#             break  # завершаем выполнение
#         print("process data:", n, item)
#
#
# q = Queue(5)  # эта очередь будет одной сразу на 2 потока!
# th1 = Thread(target=worker, args=(q, 1))
# th2 = Thread(target=worker, args=(q, 2))
# th1.start()
# th2.start()
#
# for i in range(50):
#     q.put(i)
#
# q.put(None)
# q.put(None)
# th1.join()
# th2.join()

# с точки зрения процесса ресурсами владеет именно процесс. Но процесс не знает, что там творится в потоках.
# Если поток завершить аварийно, то могут случиться неприятности (незакрытые файлы и тд).
# Поэтому в питоне нет функции аварийного завершения потока.

# Блокировки.
# import threading
#
#
# class Point:
#     def __init__(self):
#         self._mutex = threading.RLock()  # запрашиваем блокировку
#         self._x = 0
#         self._y = 0
#
#     def get(self):
#         with self._mutex:
#             return self._x, self._y
#
#     def set(self, x, y):
#         with self._mutex:
#             self._x = x
#             self._y = y

# Предположим, что используем наш класс в большом количестве потоков
# Может произойти неконсистентное состояние объекта. Также это "гонка за ресурсами"

# Другой способ
import threading

a = threading.RLock()
b = threading.RLock()


def foo():
    try:
        a.acquire()  # запрашиваем блокировку
        b.acquire()
    finally:
        a.release()  # освобождаем
        b.release()


# если мы запустим код выше в большом количестве процессов,
# то рано или поздно это приведет к ситуации, когда произойдёт взаимная блокировка (deadlock). Чтобы избежать этого
# нужно освобождать блокировки в правильной последовательности. Контекстный менеджер - это выход!

# GIL
# Глобальная блокировка интерпретатора
# Не позволяет двум потокам выполняться одновременно двум потокам. Защищает память от "разрушения".
# from threading import Thread
# import time
#
#
# def count(n):
#     while n > 0:
#         n -= 1
#
# t0 = time.time()
# count(100_00_00)
# count(100_00_00)
# print("Последовательное", time.time() - t0)
#
# # параллельное выполнение
# t0 = time.time()
# th1 = Thread(target=count, args=(100_000_000, ))
# th2 = Thread(target=count, args=(100_000_000, ))
#
# th1.start()
# th2.start()
# th1.join()
# th2.join()
#
# print("Параллельное", time.time() - t0)

# В этом случае код, который написан с использованием потоков будет неэффективным,
# так как имеем дело с CPU-bound задачами


# если заменить CPU-задачу на I/O то будет заметен огромный прирост!
